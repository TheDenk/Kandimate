{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0a11eb9-47fc-41d8-b663-ae2ffe35a158",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !git clone https://huggingface.co/kandinsky-community/kandinsky-2-2-decoder ./models/kandinsky-2-2-decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "531accca-c425-4947-8e5e-024acdbbc0e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !git clone https://huggingface.co/kandinsky-community/kandinsky-2-2-prior ./models/kandinsky-2-2-prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38246200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download models from https://drive.google.com/drive/folders/1GYMJ6ZJMljikSPkbJQNIbORqtdJjHBD0?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f9a35a1-5e74-44ee-aff8-c292e45297d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "import datetime\n",
    "import inspect\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from transformers import CLIPTextModelWithProjection, CLIPTokenizer\n",
    "from diffusers import KandinskyV22PriorPipeline, KandinskyV22Pipeline\n",
    "from diffusers import DDIMScheduler, DDPMScheduler, VQModel\n",
    "from diffusers.pipelines.kandinsky import MultilingualCLIP\n",
    "\n",
    "from kandimate.models.unet import UNet3DConditionModel\n",
    "from kandimate.pipelines.pipeline_kandimation import KandimatePipeline\n",
    "from kandimate.utils.util import save_videos_grid\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3719d8ce-7fcf-4488-9edb-5e7753dc592a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_gif_in_jupyter(gif_path, width=380):\n",
    "    from IPython import display\n",
    "    return display.HTML(f'<img src=\"{gif_path}\" width=\"{width}\">')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10002433",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "prior_path = '../models/kandinsky-2-2-prior'\n",
    "decoder_path = '../models/kandinsky-2-2-decoder'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0204b442-4f4a-41af-82e3-7c5deb68ffd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = CLIPTokenizer.from_pretrained(prior_path, subfolder='tokenizer')\n",
    "text_encoder = CLIPTextModelWithProjection.from_pretrained(\n",
    "    prior_path, \n",
    "    subfolder='text_encoder',\n",
    "    torch_dtype=torch.float16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7d3e7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = DDPMScheduler.from_pretrained(decoder_path, subfolder='scheduler')\n",
    "# scheduler = DDIMScheduler(**{\n",
    "#     'beta_start': 0.00085,\n",
    "#     'beta_end': 0.012,\n",
    "#     'beta_schedule': \"linear\",\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31805c30-36d6-4c1b-bbdc-91a435dd4dda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movq = VQModel.from_pretrained(\n",
    "    decoder_path, \n",
    "    subfolder=\"movq\", \n",
    "    torch_dtype=torch.float16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2697b100-408a-454b-aae9-0af7cd00c7e6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded temporal unet's pretrained weights from ../models/kandinsky-2-2-decoder/unet ...\n",
      "### missing keys: 1512; \n",
      "### unexpected keys: 0;\n",
      "### Motion Module Parameters: 321.823488 M\n"
     ]
    }
   ],
   "source": [
    "unet_additional_kwargs = {\n",
    "    \"use_motion_module\": True,\n",
    "    \"motion_module_resolutions\": [1, 2, 4, 8],\n",
    "    \"motion_module_mid_block\": False,\n",
    "    \"motion_module_decoder_only\": False,\n",
    "    \"motion_module_kwargs\": {\n",
    "        \"num_layers\": 2,\n",
    "        \"num_attention_heads\": 8,\n",
    "        \"temporal_position_encoding\": True,\n",
    "        \"temporal_position_encoding_max_len\": 24,\n",
    "    },\n",
    "}\n",
    "\n",
    "unet = UNet3DConditionModel.from_pretrained_2d(\n",
    "    decoder_path, \n",
    "    subfolder=\"unet\",\n",
    "    unet_additional_kwargs=unet_additional_kwargs,\n",
    ")\n",
    "unet = unet.to(dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85cd747b-e326-4cb8-afb1-14178624925a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(724, 0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motion_module = '../models/motion-modules/checkpoint-65000.ckpt'\n",
    "motion_module_state_dict = torch.load(motion_module, map_location=\"cpu\")\n",
    "\n",
    "state_dict = {}\n",
    "for name, tensor in motion_module_state_dict['state_dict'].items():\n",
    "    state_dict[name.replace('module.', '')] = tensor\n",
    "    \n",
    "missing, unexpected = unet.load_state_dict(state_dict, strict=False)\n",
    "assert len(unexpected) == 0\n",
    "len(missing), len(unexpected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "990a83e2-d0ae-4519-ba73-7ccaa636207b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = KandimatePipeline(\n",
    "    movq=movq, \n",
    "    text_encoder=text_encoder, \n",
    "    tokenizer=tokenizer, \n",
    "    unet=unet,\n",
    "    scheduler=scheduler,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e372bacb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aa28d338f4046efa77a102d22650de5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe_prior = KandinskyV22PriorPipeline.from_pretrained(\n",
    "    prior_path, torch_dtype=torch.float16\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ae916b-e4a1-40a7-ac93-03a0aaf0e247",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b363eb80faf4bfb955c176ffc84f714",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baa1a4b61519436a8c7bdac626c8a4e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72b65f801b5c4d3a8d278ebd9028e2c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3fb951a06b84a088006e83194e76452",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee7ec8c4bbc44389ae09ee6a51e4730b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f03b58611f524ce0b86b04616d683eb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bae10a2bbb94c368282c1188de32c47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dcddefe04d94a8290bf67a4b0c6f889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46cde89f7de24be998b54e7f5b2aee9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2b8279fd3b34c8fad3153cea51bfe30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e03eef953ff4545bd93a3e385457d17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa7f333a60914c7e9fbb21a66d83ba16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "IMG_H = 768\n",
    "IMG_W = 768\n",
    "TOTAL_FRAMES = 16\n",
    "\n",
    "guidance_scale = 5\n",
    "num_inference_steps = 25\n",
    "\n",
    "# seeds = [10788741199826055526, 16372571278361863751, 6519455744612555650]\n",
    "gif_count = 32\n",
    "seeds = [np.random.randint(0, np.iinfo(np.intp).max) for _ in range(gif_count)]\n",
    "\n",
    "prompts = [\n",
    "#     'pretty anime girl looking at the camera, cinematic, 4k, 8k',\n",
    "    'pretty girl looking at the camera, extremely high detail, 8k, 4k, cinematic',\n",
    "#     'pretty redhead girl looking at the camera, cinematic, extremely high detail, 8k, 4k, HQ',\n",
    "#     'train driving down a mountain railroad, cinematic, 4k, 8k',\n",
    "#     'iron man is landing, avengers, cinematic, 4k, 8k',\n",
    "]\n",
    "n_prompts = {\n",
    "#     'no': '',\n",
    "#     'short': 'low quality, bad quality',\n",
    "    'long': 'lowres, text, error, cropped, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, out of frame, extra fingers',\n",
    "}\n",
    "\n",
    "for seed in seeds:\n",
    "    samples = []\n",
    "    for neg_name, negative_prompt in n_prompts.items():\n",
    "        for prompt in prompts:\n",
    "            generator = torch.Generator(device=device).manual_seed(seed)\n",
    "\n",
    "            image_emb, zero_image_emb = pipe_prior(\n",
    "                prompt=prompt, negative_prompt=negative_prompt, generator=generator, \n",
    "            ).to_tuple()\n",
    "\n",
    "            sample = pipeline(\n",
    "                prompt,\n",
    "                image_embeds = image_emb.to(dtype=torch.float16),\n",
    "                negative_image_embeds = zero_image_emb.to(dtype=torch.float16),\n",
    "                negative_prompt = negative_prompt,\n",
    "                num_inference_steps = num_inference_steps,\n",
    "                guidance_scale = guidance_scale,\n",
    "                width = IMG_W,\n",
    "                height = IMG_H,\n",
    "                video_length = TOTAL_FRAMES,\n",
    "                generator = generator,\n",
    "                use_progress_bar = True,\n",
    "            ).videos\n",
    "\n",
    "            samples.append(sample)\n",
    "#             savedir = f'samples/generation/{seed}_{neg_name}'\n",
    "#             prompt = \"-\".join((prompt.replace(\"/\", \"\").split(\" \")[:10]))\n",
    "#             gif_path = f\"{savedir}/{prompt}.gif\"\n",
    "#             save_videos_grid(sample, gif_path)\n",
    "\n",
    "    savedir = f'samples/generation'\n",
    "    gif_path = f\"{savedir}/{seed}.gif\"\n",
    "    save_videos_grid(torch.cat(samples), gif_path, n_rows=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49415278-9019-4348-83be-4d47e8c112a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2704cc2-7e1f-4074-994e-f6e371ab8c5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfde407-f173-442f-9785-c99f5d51f98c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
